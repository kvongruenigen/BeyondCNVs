{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "96a99d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "## Intermediate file for identifiers and variant information -- Working\n",
    "# Module import\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Preparation\n",
    "\n",
    "relevant = ['Tumor_Sample_UUID','Matched_Norm_Sample_UUID','case_id', 'NCBI_Build','Chromosome',\n",
    "          'Start_Position','End_Position','Strand', 'Variant_Classification', 'Variant_Type',\n",
    "          'Reference_Allele', 'Tumor_Seq_Allele1', 'Tumor_Seq_Allele2', 'HGVSc', 'HGVSp',\n",
    "          'HGVSp_Short', 'all_effects'] # combined identifiers and variant information\n",
    "\n",
    "imf = pd.DataFrame() # Create empty dataframe for intermediate file\n",
    "\n",
    "for info in relevant: # Assign columns from relevant list\n",
    "    imf[info] = []\n",
    "\n",
    "for file in os.listdir(\"../data/\"): # Iterate through directory\n",
    "    if '.maf' in str(file): # discard MANIFEST.txt and other non-maf files\n",
    "        df = pd.read_csv(\"../data/\"+ str(file), sep='\\t', skiprows=7, header=0) # read in the maf file as df\n",
    "        df = df[relevant] # subset dataframe to relevant information\n",
    "        imf = pd.concat([imf, df]) # write the relevant information to imf\n",
    "\n",
    "imf = imf.reset_index(drop=True)\n",
    "os.makedirs('../temp', exist_ok=True) # Check for the directory\n",
    "imf.to_csv('../temp/intermediate_mapping_file.csv', index = False)  # and create .csv file in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f89aa93b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 32\u001b[0m\n\u001b[1;32m     25\u001b[0m q \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfo.legacy_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: tcga_s_id}\n\u001b[1;32m     28\u001b[0m i_e_r \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     29\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpgx:TCGA-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mtcga_c_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTCGA case_id\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     30\u001b[0m ]\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtcga_c_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mind_ids\u001b[49m:\n\u001b[1;32m     33\u001b[0m     ind_ids[tcga_c_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiosample_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(b[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Series'"
     ]
    }
   ],
   "source": [
    "## Dictionary creation for mappping -- necessary?? - yes, apparently\n",
    "\n",
    "\n",
    "################################################################################\n",
    "\n",
    "\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../temp/intermediate_mapping_file.csv')\n",
    "# identifiers = ['Tumor_Sample_UUID','Matched_Norm_Sample_UUID','case_id']\n",
    "\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.progenetixCopy ###############\n",
    "bios_coll = db[ \"biosamples\" ]\n",
    "ind_coll = db[ \"individuals\" ]\n",
    "\n",
    "ind_ids = {}\n",
    "\n",
    "tcga_s_id = df['Tumor_Sample_UUID']\n",
    "tcga_mns_id = df['Matched_Norm_Sample_UUID']\n",
    "tcga_c_id = df['case_id']\n",
    "\n",
    "q = {'info.legacy_ids': tcga_s_id}\n",
    "\n",
    "\n",
    "i_e_r = [\n",
    "    {\"id\": \"pgx:TCGA-\"+tcga_c_id, \"label\": \"TCGA case_id\"},\n",
    "]\n",
    "for line in tcga_c_id:\n",
    "    if line in ind_ids:\n",
    "        ind_ids[line][\"biosample_ids\"].append(bios_coll.find_one({'info.legacy_ids': line})[\"id\"]) #combined b an q from og code\n",
    "    else:\n",
    "        ind_ids.update({\n",
    "            tcga_c_id: {\n",
    "                \"external_references\": i_e_r,\n",
    "                \"biosample_ids\": [b[\"id\"]]\n",
    "            }\n",
    "        })\n",
    "\n",
    "b_e_r = i_e_r.copy()\n",
    "b_e_r.append({\"id\": \"pgx:TCGA-\"+tcga_s_id, \"label\": \"TCGA sample_id\"})\n",
    "\n",
    "for e in b[\"external_references\"]:\n",
    "    if not \"TCGA\" in e[\"id\"]: # <= important to keep other ers\n",
    "        b_e_r.append(e)\n",
    "    if re.match(r'^(?:pgx:)?TCGA\\-\\w+?$', e[\"id\"]):\n",
    "        project = re.sub('TCGA-', '', e[\"id\"])\n",
    "        project = re.sub('pgx:', '', project)\n",
    "        b_e_r.append({\"id\": \"pgx:TCGA-\"+project, \"label\": \"TCGA \"+project+\" project\"})\n",
    "\n",
    "if args.test:\n",
    "    print(tcga_c_id, ind_ids[tcga_c_id][\"biosample_ids\"])\n",
    "else:\n",
    "    bar.next()\n",
    "    bios_coll.update_one({\"_id\":b[\"_id\"]}, {\"$set\": {\"external_references\": b_e_r}})\n",
    "\n",
    "\n",
    "if not args.test:\n",
    "    bar.finish()\n",
    "\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ffcf91b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       becedbfd-b2aa-4dde-b7f4-29e6f59ec32c\n",
      "1       becedbfd-b2aa-4dde-b7f4-29e6f59ec32c\n",
      "2       becedbfd-b2aa-4dde-b7f4-29e6f59ec32c\n",
      "3       becedbfd-b2aa-4dde-b7f4-29e6f59ec32c\n",
      "4       becedbfd-b2aa-4dde-b7f4-29e6f59ec32c\n",
      "                        ...                 \n",
      "1409    c632675e-e8af-43cd-8744-5be3754c1c14\n",
      "1410    c632675e-e8af-43cd-8744-5be3754c1c14\n",
      "1411    c632675e-e8af-43cd-8744-5be3754c1c14\n",
      "1412    c632675e-e8af-43cd-8744-5be3754c1c14\n",
      "1413    c632675e-e8af-43cd-8744-5be3754c1c14\n",
      "Name: case_id, Length: 1414, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(tcga_c_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
